{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geo_stage_2_11x11x10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcglarry/geo/blob/master/geo_stage_2_11x11x10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kUbioL1FmGXN",
        "colab_type": "code",
        "outputId": "e7d4db3c-5be2-4fb4-d021-e01658ee3154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"ali_build_model_stage_2_MobileNetV2_aug_1000_dense.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1wSVEmcoWzRm-7B6UGkHB8ysfMDRT_xK5\n",
        "\"\"\"\n",
        "\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8aoJd93CmGao",
        "colab_type": "code",
        "outputId": "9da9c90b-8f04-4fcb-c8c3-9b5094d930b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TQX-eTtjmGhS",
        "colab_type": "code",
        "outputId": "cdb66770-0c17-4cf3-e3e3-262eb8c398f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "!ls 'drive/My Drive/geo/'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "geo_stage2_first_try.h5\t\tUntitled1.ipynb\n",
            "geo_Unet_colab.ipynb\t\tUntitled2.ipynb\n",
            "geo_Unet.ipynb\t\t\tupload_sample.csv\n",
            "test2.npy\t\t\twater_first_try_2_2.h5\n",
            "test_submit_0831_2.csv\t\twater_first_try_2.h5\n",
            "test_submit_0831_3.csv\t\twater_first_try_2_prepro_ch16.h5\n",
            "test_submit_0831_ch32.csv\twater_first_try_2_prepro_ch32_gram.h5\n",
            "test_submit_0831_ch32_gram.csv\twater_first_try_2_prepro_ch32.h5\n",
            "test_submit_0831_ch64_gram.csv\twater_first_try_2_prepro_ch64_gram.h5\n",
            "test_submit_0831.csv\t\twater_first_try_2_prepro.h5\n",
            "test_submit.csv\t\t\twater_first_try_2_prepro_twoloss.h5\n",
            "train_data.npy\t\t\twater_first_try_3_prepro.h5\n",
            "train_labels.npy\t\twater_first_try.h5\n",
            "Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cD6mcE4Zl4m1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src=  'drive/My Drive/geo/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUqwwxril4m5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pickle\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, merge, Lambda,UpSampling2D, concatenate, \\\n",
        "Conv2DTranspose,BatchNormalization\n",
        "from keras.models import Model, load_model\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhIuNLS6l4nC",
        "colab_type": "code",
        "outputId": "98275a99-239d-44b2-b94e-a842675178cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "data= np.load(src+'train_data.npy')\n",
        "label = np.load(src+'train_labels.npy')\n",
        "label = label[:,:,:,np.newaxis]\n",
        "print (data.shape)\n",
        "print (label.shape)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4200, 21, 21, 20)\n",
            "(4200, 20, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtZI1t8InGyu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reduce H,W from 21 to 11, Reduce channel from 21 to 11\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VIin_TiJl4nH",
        "colab_type": "code",
        "outputId": "d52d5919-5c12-4b9f-a94c-d376e7bd1efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "index_list_2 = list(range(20))\n",
        "select_list_2 = [idx for idx in index_list_2 if idx % 2  == 0 ]\n",
        "\n",
        "index_list_2 = list(range(21))\n",
        "select_list_0 = [idx for idx in index_list_2 if idx % 2  == 0 ]\n",
        "print (select_list_2)\n",
        "print (select_list_0)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
            "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gY3f1GFgn5gl",
        "colab_type": "code",
        "outputId": "aebccbee-72f8-4d59-9008-d81c3f7e95b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = data[:,:,:,select_list_2]\n",
        "\n",
        "data = data[:,select_list_0,:,:]\n",
        "\n",
        "data = data[:,:,select_list_0,:]\n",
        "data.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4200, 11, 11, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Zlc2JmA2w_RG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_mean = np.mean(data)\n",
        "data_std = np.std(data)\n",
        "label_max = np.max(label)\n",
        "label_min = np.min(label)\n",
        "\n",
        "train_data = (data - data_mean)/data_std\n",
        "#label_data = (label-label_min)/(label_max - label_min)\n",
        "label_data = np.log(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGeIz5AWl4nL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x,val_x,train_y,val_y = train_test_split(train_data,label_data,test_size=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l_F7YnLWqzBU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_block(ch, activation= 'relu', padding='same',kernel_regularizer=regularizers.l2(0.01)):       \n",
        "    return Conv2D(ch,(3,3),activation= activation, padding =padding )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C8sDm7fZl4nQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def build_model_1(IMAGE_HEIGHT=IMAGE_HEIGHT,IMAGE_WIDTH=IMAGE_WIDTH,ch=ch):\n",
        "def build_model_1(ch=8):\n",
        "    #inputs = Input((IMAGE_HEIGHT,IMAGE_WIDTH,ch))\n",
        "    inputs = Input((11,11,10))\n",
        "    \n",
        "    up_1 = UpSampling2D(size=(2,2))(inputs)\n",
        "\n",
        "    conv0 = Conv2D(32,(3,3),padding='valid')(up_1)\n",
        "    print ('conv0',conv0.get_shape())\n",
        "    conv1 =  conv_block(ch)(conv0)\n",
        "    conv1 = conv_block(ch)(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
        "    print ('pool1',pool1.get_shape())\n",
        "    \n",
        "    conv2 =  conv_block(ch*2)(pool1)\n",
        "    conv2 = conv_block(ch*2)(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
        "    print ('poo12',pool2.get_shape())\n",
        "    \n",
        "    conv_test = Conv2D(64,(2,2),padding='valid')(pool2)\n",
        "    print ('conv_test',conv_test.get_shape())\n",
        "    \n",
        "    \n",
        "    \n",
        "    conv3 =  conv_block(ch*4)(conv_test)\n",
        "    conv3 = conv_block(ch*4)(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
        "    print ('poo13',pool3.get_shape())\n",
        "    \n",
        "    conv4 =  conv_block(ch*8)(pool3)\n",
        "    conv4 = conv_block(ch*8)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
        "    print ('poo14',pool4.get_shape())\n",
        "    \n",
        "    conv5 =  conv_block(ch*16)(pool4)\n",
        "    conv5 = conv_block(ch*16)(conv5)\n",
        "\n",
        "    \n",
        "    up6 = concatenate([UpSampling2D(size=(2,2))(conv5), conv4], axis=3)\n",
        "    conv6 = conv_block(ch*8)(up6)\n",
        "    conv6 = conv_block(ch*8)(conv6)\n",
        "    \n",
        "    up7 = concatenate ([UpSampling2D(size=(2,2))(conv6), conv3],  axis=3)\n",
        "    conv7 = conv_block(ch*4)(up7)\n",
        "    conv7 = conv_block(ch*4)(conv7)\n",
        "    print ('conv7',conv7.get_shape())\n",
        "    conv7 = Conv2DTranspose(ch*4,(2,2),padding='valid')(conv7)\n",
        "    print ('conv7',conv7.get_shape())\n",
        "    \n",
        "    up8 = concatenate([UpSampling2D(size=(2,2))(conv7), conv2], axis=3)\n",
        "    conv8 = conv_block(ch*2)(up8)\n",
        "    conv8 = conv_block(ch*2)(conv8)\n",
        "    \n",
        "    up9 = concatenate([UpSampling2D(size=(2,2))(conv8), conv1],  axis=3)\n",
        "    conv9 = conv_block(ch)(up9)\n",
        "    conv9 = conv_block(ch)(conv9)\n",
        "    \n",
        "    \n",
        "    \n",
        "    conv10 = Conv2D(1,(1,1))(conv9)\n",
        "    \n",
        "  \n",
        "    model = Model(inputs= inputs, outputs=conv10)\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqpLnCCCoXnF",
        "colab_type": "code",
        "outputId": "1e1928eb-4db1-4ecc-dede-d8c277521e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1634
        }
      },
      "cell_type": "code",
      "source": [
        "model = build_model_1()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv0 (?, 20, 20, 32)\n",
            "pool1 (?, 10, 10, 8)\n",
            "poo12 (?, 5, 5, 16)\n",
            "conv_test (?, 4, 4, 64)\n",
            "poo13 (?, 2, 2, 32)\n",
            "poo14 (?, 1, 1, 64)\n",
            "conv7 (?, 4, 4, 32)\n",
            "conv7 (?, ?, ?, 32)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 11, 11, 10)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 22, 22, 10)   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 32)   2912        up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 20, 20, 8)    2312        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 8)    584         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 8)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 10, 10, 16)   1168        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 10, 10, 16)   2320        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 16)     0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 4, 4, 64)     4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 4, 4, 32)     18464       conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 4, 4, 32)     9248        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 32)     0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 2, 2, 64)     18496       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 2, 2, 64)     36928       conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 1, 1, 128)    73856       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 1, 1, 128)    147584      conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 2, 2, 128)    0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2, 2, 192)    0           up_sampling2d_3[0][0]            \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 2, 2, 64)     110656      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 2, 2, 64)     36928       conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 4, 4, 64)     0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4, 4, 96)     0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 32)     27680       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 32)     9248        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 5, 5, 32)     4128        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 10, 10, 32)   0           conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 10, 10, 48)   0           up_sampling2d_5[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 10, 10, 16)   6928        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 10, 10, 16)   2320        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 20, 20, 16)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 20, 20, 24)   0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 20, 20, 8)    1736        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 20, 20, 8)    584         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 20, 20, 1)    9           conv2d_21[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 518,249\n",
            "Trainable params: 518,249\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTSiLPYtl4nU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile (optimizer='Adam', loss = 'mse', metrics =['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQ1YM-aml4nZ",
        "colab_type": "code",
        "outputId": "107fafd6-4b5b-4fe3-8a94-c01d38ae2de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# train the model on the new data for a few epochs\n",
        "\n",
        "use_model= False\n",
        "if use_model:\n",
        "    \n",
        "\n",
        "    if os.path.isfile(src+'water_first_try.h5'):\n",
        "\n",
        "      model = load_model(src+'water_first_try.h5')\n",
        "      print ('model laoded')\n",
        "    else:\n",
        "      print ('model not exist')\n",
        "else:\n",
        "  print ('not to use model')\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not to use model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2NKk1wFl4nc",
        "colab_type": "code",
        "outputId": "8c4437dd-9d2a-4723-de08-ee0681c3cf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4958
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=src+'geo_stage2_first_try_11_11_10.h5', monitor = 'val_loss', save_best_only=True, mode= 'auto')\n",
        "earlystop = EarlyStopping(patience=30)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=15, min_lr=0.00001,verbose=1)\n",
        "callback_list = [checkpoint, earlystop,reduce_lr]\n",
        "model.fit(x=train_x, y=train_y, batch_size=32, epochs=1000, callbacks = callback_list, verbose=1, validation_split=0.2,  shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2688 samples, validate on 672 samples\n",
            "Epoch 1/1000\n",
            "2688/2688 [==============================] - 5s 2ms/step - loss: 0.8644 - mean_absolute_error: 0.7322 - val_loss: 0.5979 - val_mean_absolute_error: 0.6109\n",
            "Epoch 2/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.5026 - mean_absolute_error: 0.5581 - val_loss: 0.4319 - val_mean_absolute_error: 0.5158\n",
            "Epoch 3/1000\n",
            "2688/2688 [==============================] - 2s 895us/step - loss: 0.3862 - mean_absolute_error: 0.4868 - val_loss: 0.3464 - val_mean_absolute_error: 0.4603\n",
            "Epoch 4/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.3319 - mean_absolute_error: 0.4510 - val_loss: 0.3297 - val_mean_absolute_error: 0.4526\n",
            "Epoch 5/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.3013 - mean_absolute_error: 0.4297 - val_loss: 0.2929 - val_mean_absolute_error: 0.4218\n",
            "Epoch 6/1000\n",
            "2688/2688 [==============================] - 2s 894us/step - loss: 0.2785 - mean_absolute_error: 0.4128 - val_loss: 0.2661 - val_mean_absolute_error: 0.4032\n",
            "Epoch 7/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.2620 - mean_absolute_error: 0.4001 - val_loss: 0.2570 - val_mean_absolute_error: 0.3949\n",
            "Epoch 8/1000\n",
            "2688/2688 [==============================] - 2s 889us/step - loss: 0.2499 - mean_absolute_error: 0.3908 - val_loss: 0.2429 - val_mean_absolute_error: 0.3848\n",
            "Epoch 9/1000\n",
            "2688/2688 [==============================] - 2s 896us/step - loss: 0.2426 - mean_absolute_error: 0.3848 - val_loss: 0.2383 - val_mean_absolute_error: 0.3805\n",
            "Epoch 10/1000\n",
            "2688/2688 [==============================] - 2s 875us/step - loss: 0.2336 - mean_absolute_error: 0.3776 - val_loss: 0.2332 - val_mean_absolute_error: 0.3760\n",
            "Epoch 11/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.2239 - mean_absolute_error: 0.3693 - val_loss: 0.2251 - val_mean_absolute_error: 0.3697\n",
            "Epoch 12/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.2198 - mean_absolute_error: 0.3662 - val_loss: 0.2231 - val_mean_absolute_error: 0.3673\n",
            "Epoch 13/1000\n",
            "2688/2688 [==============================] - 2s 889us/step - loss: 0.2130 - mean_absolute_error: 0.3602 - val_loss: 0.2201 - val_mean_absolute_error: 0.3653\n",
            "Epoch 14/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.2084 - mean_absolute_error: 0.3565 - val_loss: 0.2136 - val_mean_absolute_error: 0.3599\n",
            "Epoch 15/1000\n",
            "2688/2688 [==============================] - 2s 891us/step - loss: 0.2045 - mean_absolute_error: 0.3532 - val_loss: 0.2100 - val_mean_absolute_error: 0.3569\n",
            "Epoch 16/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.2000 - mean_absolute_error: 0.3491 - val_loss: 0.2056 - val_mean_absolute_error: 0.3539\n",
            "Epoch 17/1000\n",
            "2688/2688 [==============================] - 2s 891us/step - loss: 0.1973 - mean_absolute_error: 0.3468 - val_loss: 0.1988 - val_mean_absolute_error: 0.3474\n",
            "Epoch 18/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1931 - mean_absolute_error: 0.3432 - val_loss: 0.1974 - val_mean_absolute_error: 0.3463\n",
            "Epoch 19/1000\n",
            "2688/2688 [==============================] - 2s 875us/step - loss: 0.1885 - mean_absolute_error: 0.3388 - val_loss: 0.1921 - val_mean_absolute_error: 0.3415\n",
            "Epoch 20/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1856 - mean_absolute_error: 0.3365 - val_loss: 0.1909 - val_mean_absolute_error: 0.3410\n",
            "Epoch 21/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1825 - mean_absolute_error: 0.3337 - val_loss: 0.1902 - val_mean_absolute_error: 0.3398\n",
            "Epoch 22/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1818 - mean_absolute_error: 0.3331 - val_loss: 0.1898 - val_mean_absolute_error: 0.3395\n",
            "Epoch 23/1000\n",
            "2688/2688 [==============================] - 2s 882us/step - loss: 0.1769 - mean_absolute_error: 0.3284 - val_loss: 0.1882 - val_mean_absolute_error: 0.3375\n",
            "Epoch 24/1000\n",
            "2688/2688 [==============================] - 2s 882us/step - loss: 0.1767 - mean_absolute_error: 0.3283 - val_loss: 0.1847 - val_mean_absolute_error: 0.3355\n",
            "Epoch 25/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1735 - mean_absolute_error: 0.3255 - val_loss: 0.1825 - val_mean_absolute_error: 0.3323\n",
            "Epoch 26/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1704 - mean_absolute_error: 0.3224 - val_loss: 0.1795 - val_mean_absolute_error: 0.3298\n",
            "Epoch 27/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1671 - mean_absolute_error: 0.3194 - val_loss: 0.1816 - val_mean_absolute_error: 0.3315\n",
            "Epoch 28/1000\n",
            "2688/2688 [==============================] - 2s 901us/step - loss: 0.1678 - mean_absolute_error: 0.3202 - val_loss: 0.1785 - val_mean_absolute_error: 0.3287\n",
            "Epoch 29/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1655 - mean_absolute_error: 0.3181 - val_loss: 0.1751 - val_mean_absolute_error: 0.3260\n",
            "Epoch 30/1000\n",
            "2688/2688 [==============================] - 2s 895us/step - loss: 0.1646 - mean_absolute_error: 0.3171 - val_loss: 0.1820 - val_mean_absolute_error: 0.3328\n",
            "Epoch 31/1000\n",
            "2688/2688 [==============================] - 2s 888us/step - loss: 0.1608 - mean_absolute_error: 0.3136 - val_loss: 0.1744 - val_mean_absolute_error: 0.3248\n",
            "Epoch 32/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1580 - mean_absolute_error: 0.3106 - val_loss: 0.1733 - val_mean_absolute_error: 0.3235\n",
            "Epoch 33/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1588 - mean_absolute_error: 0.3116 - val_loss: 0.1741 - val_mean_absolute_error: 0.3244\n",
            "Epoch 34/1000\n",
            "2688/2688 [==============================] - 2s 889us/step - loss: 0.1567 - mean_absolute_error: 0.3096 - val_loss: 0.1730 - val_mean_absolute_error: 0.3236\n",
            "Epoch 35/1000\n",
            "2688/2688 [==============================] - 2s 899us/step - loss: 0.1546 - mean_absolute_error: 0.3075 - val_loss: 0.1722 - val_mean_absolute_error: 0.3234\n",
            "Epoch 36/1000\n",
            "2688/2688 [==============================] - 2s 898us/step - loss: 0.1546 - mean_absolute_error: 0.3075 - val_loss: 0.1749 - val_mean_absolute_error: 0.3263\n",
            "Epoch 37/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1540 - mean_absolute_error: 0.3071 - val_loss: 0.1696 - val_mean_absolute_error: 0.3201\n",
            "Epoch 38/1000\n",
            "2688/2688 [==============================] - 2s 893us/step - loss: 0.1511 - mean_absolute_error: 0.3041 - val_loss: 0.1721 - val_mean_absolute_error: 0.3227\n",
            "Epoch 39/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1511 - mean_absolute_error: 0.3042 - val_loss: 0.1695 - val_mean_absolute_error: 0.3203\n",
            "Epoch 40/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1486 - mean_absolute_error: 0.3016 - val_loss: 0.1640 - val_mean_absolute_error: 0.3149\n",
            "Epoch 41/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1490 - mean_absolute_error: 0.3020 - val_loss: 0.1713 - val_mean_absolute_error: 0.3222\n",
            "Epoch 42/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1470 - mean_absolute_error: 0.3000 - val_loss: 0.1705 - val_mean_absolute_error: 0.3209\n",
            "Epoch 43/1000\n",
            "2688/2688 [==============================] - 2s 894us/step - loss: 0.1465 - mean_absolute_error: 0.2995 - val_loss: 0.1657 - val_mean_absolute_error: 0.3165\n",
            "Epoch 44/1000\n",
            "2688/2688 [==============================] - 2s 897us/step - loss: 0.1448 - mean_absolute_error: 0.2978 - val_loss: 0.1690 - val_mean_absolute_error: 0.3201\n",
            "Epoch 45/1000\n",
            "2688/2688 [==============================] - 2s 901us/step - loss: 0.1456 - mean_absolute_error: 0.2987 - val_loss: 0.1687 - val_mean_absolute_error: 0.3200\n",
            "Epoch 46/1000\n",
            "2688/2688 [==============================] - 2s 889us/step - loss: 0.1432 - mean_absolute_error: 0.2962 - val_loss: 0.1645 - val_mean_absolute_error: 0.3150\n",
            "Epoch 47/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1420 - mean_absolute_error: 0.2951 - val_loss: 0.1694 - val_mean_absolute_error: 0.3196\n",
            "Epoch 48/1000\n",
            "2688/2688 [==============================] - 2s 895us/step - loss: 0.1413 - mean_absolute_error: 0.2945 - val_loss: 0.1641 - val_mean_absolute_error: 0.3149\n",
            "Epoch 49/1000\n",
            "2688/2688 [==============================] - 2s 896us/step - loss: 0.1392 - mean_absolute_error: 0.2922 - val_loss: 0.1624 - val_mean_absolute_error: 0.3138\n",
            "Epoch 50/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1386 - mean_absolute_error: 0.2917 - val_loss: 0.1638 - val_mean_absolute_error: 0.3143\n",
            "Epoch 51/1000\n",
            "2688/2688 [==============================] - 2s 883us/step - loss: 0.1383 - mean_absolute_error: 0.2913 - val_loss: 0.1621 - val_mean_absolute_error: 0.3128\n",
            "Epoch 52/1000\n",
            "2688/2688 [==============================] - 2s 891us/step - loss: 0.1391 - mean_absolute_error: 0.2921 - val_loss: 0.1646 - val_mean_absolute_error: 0.3156\n",
            "Epoch 53/1000\n",
            "2688/2688 [==============================] - 2s 893us/step - loss: 0.1376 - mean_absolute_error: 0.2905 - val_loss: 0.1614 - val_mean_absolute_error: 0.3123\n",
            "Epoch 54/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1359 - mean_absolute_error: 0.2888 - val_loss: 0.1614 - val_mean_absolute_error: 0.3125\n",
            "Epoch 55/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1347 - mean_absolute_error: 0.2876 - val_loss: 0.1617 - val_mean_absolute_error: 0.3121\n",
            "Epoch 56/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1367 - mean_absolute_error: 0.2898 - val_loss: 0.1618 - val_mean_absolute_error: 0.3134\n",
            "Epoch 57/1000\n",
            "2688/2688 [==============================] - 2s 895us/step - loss: 0.1335 - mean_absolute_error: 0.2863 - val_loss: 0.1596 - val_mean_absolute_error: 0.3105\n",
            "Epoch 58/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1342 - mean_absolute_error: 0.2872 - val_loss: 0.1598 - val_mean_absolute_error: 0.3105\n",
            "Epoch 59/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1323 - mean_absolute_error: 0.2850 - val_loss: 0.1629 - val_mean_absolute_error: 0.3142\n",
            "Epoch 60/1000\n",
            "2688/2688 [==============================] - 2s 888us/step - loss: 0.1344 - mean_absolute_error: 0.2874 - val_loss: 0.1625 - val_mean_absolute_error: 0.3129\n",
            "Epoch 61/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1344 - mean_absolute_error: 0.2874 - val_loss: 0.1601 - val_mean_absolute_error: 0.3105\n",
            "Epoch 62/1000\n",
            "2688/2688 [==============================] - 2s 895us/step - loss: 0.1324 - mean_absolute_error: 0.2853 - val_loss: 0.1610 - val_mean_absolute_error: 0.3123\n",
            "Epoch 63/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1301 - mean_absolute_error: 0.2828 - val_loss: 0.1619 - val_mean_absolute_error: 0.3136\n",
            "Epoch 64/1000\n",
            "2688/2688 [==============================] - 2s 882us/step - loss: 0.1291 - mean_absolute_error: 0.2817 - val_loss: 0.1587 - val_mean_absolute_error: 0.3094\n",
            "Epoch 65/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1289 - mean_absolute_error: 0.2814 - val_loss: 0.1599 - val_mean_absolute_error: 0.3106\n",
            "Epoch 66/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1303 - mean_absolute_error: 0.2831 - val_loss: 0.1598 - val_mean_absolute_error: 0.3102\n",
            "Epoch 67/1000\n",
            "2688/2688 [==============================] - 2s 873us/step - loss: 0.1286 - mean_absolute_error: 0.2811 - val_loss: 0.1613 - val_mean_absolute_error: 0.3116\n",
            "Epoch 68/1000\n",
            "2688/2688 [==============================] - 2s 869us/step - loss: 0.1305 - mean_absolute_error: 0.2833 - val_loss: 0.1582 - val_mean_absolute_error: 0.3088\n",
            "Epoch 69/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1275 - mean_absolute_error: 0.2799 - val_loss: 0.1580 - val_mean_absolute_error: 0.3084\n",
            "Epoch 70/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1301 - mean_absolute_error: 0.2829 - val_loss: 0.1611 - val_mean_absolute_error: 0.3117\n",
            "Epoch 71/1000\n",
            "2688/2688 [==============================] - 2s 889us/step - loss: 0.1273 - mean_absolute_error: 0.2798 - val_loss: 0.1599 - val_mean_absolute_error: 0.3105\n",
            "Epoch 72/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1289 - mean_absolute_error: 0.2815 - val_loss: 0.1616 - val_mean_absolute_error: 0.3118\n",
            "Epoch 73/1000\n",
            "2688/2688 [==============================] - 2s 892us/step - loss: 0.1261 - mean_absolute_error: 0.2785 - val_loss: 0.1620 - val_mean_absolute_error: 0.3130\n",
            "Epoch 74/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1254 - mean_absolute_error: 0.2778 - val_loss: 0.1629 - val_mean_absolute_error: 0.3131\n",
            "Epoch 75/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1262 - mean_absolute_error: 0.2786 - val_loss: 0.1613 - val_mean_absolute_error: 0.3117\n",
            "Epoch 76/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1231 - mean_absolute_error: 0.2752 - val_loss: 0.1573 - val_mean_absolute_error: 0.3080\n",
            "Epoch 77/1000\n",
            "2688/2688 [==============================] - 2s 894us/step - loss: 0.1232 - mean_absolute_error: 0.2754 - val_loss: 0.1590 - val_mean_absolute_error: 0.3098\n",
            "Epoch 78/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1224 - mean_absolute_error: 0.2745 - val_loss: 0.1569 - val_mean_absolute_error: 0.3076\n",
            "Epoch 79/1000\n",
            "2688/2688 [==============================] - 2s 882us/step - loss: 0.1225 - mean_absolute_error: 0.2745 - val_loss: 0.1576 - val_mean_absolute_error: 0.3082\n",
            "Epoch 80/1000\n",
            "2688/2688 [==============================] - 2s 882us/step - loss: 0.1224 - mean_absolute_error: 0.2745 - val_loss: 0.1575 - val_mean_absolute_error: 0.3081\n",
            "Epoch 81/1000\n",
            "2688/2688 [==============================] - 2s 883us/step - loss: 0.1213 - mean_absolute_error: 0.2733 - val_loss: 0.1639 - val_mean_absolute_error: 0.3137\n",
            "Epoch 82/1000\n",
            "2688/2688 [==============================] - 2s 893us/step - loss: 0.1218 - mean_absolute_error: 0.2739 - val_loss: 0.1585 - val_mean_absolute_error: 0.3090\n",
            "Epoch 83/1000\n",
            "2688/2688 [==============================] - 2s 894us/step - loss: 0.1230 - mean_absolute_error: 0.2752 - val_loss: 0.1591 - val_mean_absolute_error: 0.3097\n",
            "Epoch 84/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1219 - mean_absolute_error: 0.2740 - val_loss: 0.1590 - val_mean_absolute_error: 0.3095\n",
            "Epoch 85/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1212 - mean_absolute_error: 0.2731 - val_loss: 0.1572 - val_mean_absolute_error: 0.3074\n",
            "Epoch 86/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1199 - mean_absolute_error: 0.2718 - val_loss: 0.1572 - val_mean_absolute_error: 0.3078\n",
            "Epoch 87/1000\n",
            "2688/2688 [==============================] - 2s 889us/step - loss: 0.1216 - mean_absolute_error: 0.2738 - val_loss: 0.1594 - val_mean_absolute_error: 0.3094\n",
            "Epoch 88/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1201 - mean_absolute_error: 0.2720 - val_loss: 0.1571 - val_mean_absolute_error: 0.3073\n",
            "Epoch 89/1000\n",
            "2688/2688 [==============================] - 2s 892us/step - loss: 0.1184 - mean_absolute_error: 0.2700 - val_loss: 0.1565 - val_mean_absolute_error: 0.3071\n",
            "Epoch 90/1000\n",
            "2688/2688 [==============================] - 2s 900us/step - loss: 0.1187 - mean_absolute_error: 0.2704 - val_loss: 0.1625 - val_mean_absolute_error: 0.3132\n",
            "Epoch 91/1000\n",
            "2688/2688 [==============================] - 2s 896us/step - loss: 0.1192 - mean_absolute_error: 0.2709 - val_loss: 0.1591 - val_mean_absolute_error: 0.3093\n",
            "Epoch 92/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1193 - mean_absolute_error: 0.2712 - val_loss: 0.1638 - val_mean_absolute_error: 0.3142\n",
            "Epoch 93/1000\n",
            "2688/2688 [==============================] - 2s 891us/step - loss: 0.1193 - mean_absolute_error: 0.2711 - val_loss: 0.1602 - val_mean_absolute_error: 0.3106\n",
            "Epoch 94/1000\n",
            "2688/2688 [==============================] - 2s 902us/step - loss: 0.1185 - mean_absolute_error: 0.2703 - val_loss: 0.1602 - val_mean_absolute_error: 0.3098\n",
            "Epoch 95/1000\n",
            "2688/2688 [==============================] - 2s 882us/step - loss: 0.1193 - mean_absolute_error: 0.2712 - val_loss: 0.1599 - val_mean_absolute_error: 0.3102\n",
            "Epoch 96/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1175 - mean_absolute_error: 0.2691 - val_loss: 0.1602 - val_mean_absolute_error: 0.3103\n",
            "Epoch 97/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1171 - mean_absolute_error: 0.2687 - val_loss: 0.1591 - val_mean_absolute_error: 0.3100\n",
            "Epoch 98/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1174 - mean_absolute_error: 0.2691 - val_loss: 0.1594 - val_mean_absolute_error: 0.3094\n",
            "Epoch 99/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1156 - mean_absolute_error: 0.2668 - val_loss: 0.1566 - val_mean_absolute_error: 0.3068\n",
            "Epoch 100/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1149 - mean_absolute_error: 0.2661 - val_loss: 0.1580 - val_mean_absolute_error: 0.3080\n",
            "Epoch 101/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1161 - mean_absolute_error: 0.2675 - val_loss: 0.1645 - val_mean_absolute_error: 0.3143\n",
            "Epoch 102/1000\n",
            "2688/2688 [==============================] - 2s 892us/step - loss: 0.1166 - mean_absolute_error: 0.2681 - val_loss: 0.1583 - val_mean_absolute_error: 0.3086\n",
            "Epoch 103/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1153 - mean_absolute_error: 0.2666 - val_loss: 0.1587 - val_mean_absolute_error: 0.3090\n",
            "Epoch 104/1000\n",
            "2688/2688 [==============================] - 2s 892us/step - loss: 0.1175 - mean_absolute_error: 0.2692 - val_loss: 0.1589 - val_mean_absolute_error: 0.3089\n",
            "\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 105/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1112 - mean_absolute_error: 0.2616 - val_loss: 0.1557 - val_mean_absolute_error: 0.3058\n",
            "Epoch 106/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1090 - mean_absolute_error: 0.2591 - val_loss: 0.1571 - val_mean_absolute_error: 0.3075\n",
            "Epoch 107/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1082 - mean_absolute_error: 0.2581 - val_loss: 0.1561 - val_mean_absolute_error: 0.3060\n",
            "Epoch 108/1000\n",
            "2688/2688 [==============================] - 2s 888us/step - loss: 0.1079 - mean_absolute_error: 0.2577 - val_loss: 0.1570 - val_mean_absolute_error: 0.3069\n",
            "Epoch 109/1000\n",
            "2688/2688 [==============================] - 2s 896us/step - loss: 0.1077 - mean_absolute_error: 0.2576 - val_loss: 0.1569 - val_mean_absolute_error: 0.3067\n",
            "Epoch 110/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1071 - mean_absolute_error: 0.2569 - val_loss: 0.1567 - val_mean_absolute_error: 0.3067\n",
            "Epoch 111/1000\n",
            "2688/2688 [==============================] - 2s 877us/step - loss: 0.1070 - mean_absolute_error: 0.2568 - val_loss: 0.1571 - val_mean_absolute_error: 0.3068\n",
            "Epoch 112/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1068 - mean_absolute_error: 0.2565 - val_loss: 0.1578 - val_mean_absolute_error: 0.3077\n",
            "Epoch 113/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1067 - mean_absolute_error: 0.2564 - val_loss: 0.1583 - val_mean_absolute_error: 0.3082\n",
            "Epoch 114/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1066 - mean_absolute_error: 0.2563 - val_loss: 0.1580 - val_mean_absolute_error: 0.3079\n",
            "Epoch 115/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1066 - mean_absolute_error: 0.2563 - val_loss: 0.1578 - val_mean_absolute_error: 0.3078\n",
            "Epoch 116/1000\n",
            "2688/2688 [==============================] - 2s 893us/step - loss: 0.1063 - mean_absolute_error: 0.2559 - val_loss: 0.1586 - val_mean_absolute_error: 0.3084\n",
            "Epoch 117/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1062 - mean_absolute_error: 0.2559 - val_loss: 0.1587 - val_mean_absolute_error: 0.3085\n",
            "Epoch 118/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1065 - mean_absolute_error: 0.2562 - val_loss: 0.1586 - val_mean_absolute_error: 0.3085\n",
            "Epoch 119/1000\n",
            "2688/2688 [==============================] - 2s 893us/step - loss: 0.1062 - mean_absolute_error: 0.2558 - val_loss: 0.1589 - val_mean_absolute_error: 0.3087\n",
            "Epoch 120/1000\n",
            "2688/2688 [==============================] - 2s 883us/step - loss: 0.1062 - mean_absolute_error: 0.2559 - val_loss: 0.1596 - val_mean_absolute_error: 0.3095\n",
            "\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 121/1000\n",
            "2688/2688 [==============================] - 2s 885us/step - loss: 0.1043 - mean_absolute_error: 0.2535 - val_loss: 0.1586 - val_mean_absolute_error: 0.3084\n",
            "Epoch 122/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1036 - mean_absolute_error: 0.2526 - val_loss: 0.1586 - val_mean_absolute_error: 0.3084\n",
            "Epoch 123/1000\n",
            "2688/2688 [==============================] - 2s 873us/step - loss: 0.1034 - mean_absolute_error: 0.2524 - val_loss: 0.1589 - val_mean_absolute_error: 0.3087\n",
            "Epoch 124/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1031 - mean_absolute_error: 0.2521 - val_loss: 0.1592 - val_mean_absolute_error: 0.3090\n",
            "Epoch 125/1000\n",
            "2688/2688 [==============================] - 2s 883us/step - loss: 0.1031 - mean_absolute_error: 0.2520 - val_loss: 0.1602 - val_mean_absolute_error: 0.3101\n",
            "Epoch 126/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1029 - mean_absolute_error: 0.2518 - val_loss: 0.1597 - val_mean_absolute_error: 0.3095\n",
            "Epoch 127/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1028 - mean_absolute_error: 0.2517 - val_loss: 0.1598 - val_mean_absolute_error: 0.3095\n",
            "Epoch 128/1000\n",
            "2688/2688 [==============================] - 2s 887us/step - loss: 0.1027 - mean_absolute_error: 0.2515 - val_loss: 0.1602 - val_mean_absolute_error: 0.3101\n",
            "Epoch 129/1000\n",
            "2688/2688 [==============================] - 2s 884us/step - loss: 0.1027 - mean_absolute_error: 0.2515 - val_loss: 0.1604 - val_mean_absolute_error: 0.3100\n",
            "Epoch 130/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1025 - mean_absolute_error: 0.2513 - val_loss: 0.1601 - val_mean_absolute_error: 0.3099\n",
            "Epoch 131/1000\n",
            "2688/2688 [==============================] - 2s 886us/step - loss: 0.1023 - mean_absolute_error: 0.2511 - val_loss: 0.1606 - val_mean_absolute_error: 0.3104\n",
            "Epoch 132/1000\n",
            "2688/2688 [==============================] - 2s 881us/step - loss: 0.1023 - mean_absolute_error: 0.2511 - val_loss: 0.1611 - val_mean_absolute_error: 0.3110\n",
            "Epoch 133/1000\n",
            "2688/2688 [==============================] - 2s 879us/step - loss: 0.1023 - mean_absolute_error: 0.2510 - val_loss: 0.1604 - val_mean_absolute_error: 0.3101\n",
            "Epoch 134/1000\n",
            "2688/2688 [==============================] - 2s 880us/step - loss: 0.1022 - mean_absolute_error: 0.2509 - val_loss: 0.1613 - val_mean_absolute_error: 0.3109\n",
            "Epoch 135/1000\n",
            "2688/2688 [==============================] - 2s 890us/step - loss: 0.1021 - mean_absolute_error: 0.2509 - val_loss: 0.1612 - val_mean_absolute_error: 0.3108\n",
            "\n",
            "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4e3dff7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "RfvCtJTd5bsr",
        "colab_type": "code",
        "outputId": "3a2b4b32-33cb-4d83-f98b-a1033782afa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "error = model.evaluate(val_x,val_y)\n",
        "print (error)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "840/840 [==============================] - 0s 272us/step\n",
            "[0.1610054027466547, 0.31099959924107506]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5CWRCpqll4ni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(val_x,val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ep90s0lsl4nn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "with open('train_data.pickle', 'wb') as f:\n",
        "    pickle.dump(train_data, f)"
      ]
    },
    {
      "metadata": {
        "id": "FEVS2wr1l4np",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "with open('train_data.pickle', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "print (train_data.shape)    \n"
      ]
    },
    {
      "metadata": {
        "id": "_mgkvCKEl4n6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}